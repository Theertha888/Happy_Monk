{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encode the target variable\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the deep learning model with trainable coefficients\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Define the coefficients as trainable variables\n",
        "k0 = tf.Variable(initial_value=tf.random.normal([1]), trainable=True)\n",
        "k1 = tf.Variable(initial_value=tf.random.normal([1]), trainable=True)\n",
        "k2 = tf.Variable(initial_value=tf.random.normal([1]), trainable=True)\n",
        "\n",
        "# Define the custom activation function\n",
        "def custom_activation(x):\n",
        "    return k0 + k1 * tf.nn.relu(x) + k2 * tf.square(tf.nn.relu(x))\n",
        "\n",
        "# Set the activation function for the desired layers\n",
        "model.layers[0].activation = custom_activation\n",
        "model.layers[1].activation = custom_activation\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "# Print the learned coefficients\n",
        "print('Learned Coefficients:')\n",
        "print(f'k0: {k0.numpy()[0]:.4f}')\n",
        "print(f'k1: {k1.numpy()[0]:.4f}')\n",
        "print(f'k2: {k2.numpy()[0]:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtXcbo88jS_B",
        "outputId": "8d64e68a-fefa-43a0-8bc0-1128731b5f4b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 2s 5ms/step - loss: 1.8769 - accuracy: 0.3417\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4962 - accuracy: 0.3750\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1723 - accuracy: 0.4333\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9317 - accuracy: 0.4917\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7449 - accuracy: 0.5583\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6209 - accuracy: 0.6917\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5512 - accuracy: 0.7833\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.8167\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.8333\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.8333\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8583\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8667\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8583\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8583\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8500\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3630 - accuracy: 0.8583\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3512 - accuracy: 0.8667\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3445 - accuracy: 0.8667\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.3344 - accuracy: 0.8667\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.3282 - accuracy: 0.8667\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.3196 - accuracy: 0.8667\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3108 - accuracy: 0.8750\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.3036 - accuracy: 0.8667\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2982 - accuracy: 0.8667\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2937 - accuracy: 0.8667\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2863 - accuracy: 0.8833\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2773 - accuracy: 0.8833\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2730 - accuracy: 0.8917\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2646 - accuracy: 0.8750\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2600 - accuracy: 0.8833\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.8833\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2460 - accuracy: 0.8917\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2405 - accuracy: 0.9083\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2363 - accuracy: 0.9083\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2288 - accuracy: 0.9083\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2235 - accuracy: 0.9083\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2154 - accuracy: 0.9167\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2186 - accuracy: 0.9083\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2112 - accuracy: 0.9083\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2000 - accuracy: 0.9083\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1950 - accuracy: 0.9083\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1893 - accuracy: 0.9167\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1839 - accuracy: 0.9333\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1788 - accuracy: 0.9333\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1749 - accuracy: 0.9250\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1725 - accuracy: 0.9333\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1669 - accuracy: 0.9333\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1623 - accuracy: 0.9333\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1611 - accuracy: 0.9250\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1625 - accuracy: 0.9417\n",
            "Test Loss: 0.1143\n",
            "Test Accuracy: 1.0000\n",
            "Learned Coefficients:\n",
            "k0: 1.1356\n",
            "k1: 0.7402\n",
            "k2: -0.4396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GbSOFSt_jTBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lO1GNqUqjTC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vyECdH8WjTE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LL8xoDQjTHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ceedKcNjTJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0npQdl4jTMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_52jc38IjTOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKprct-gjTRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D12o3jywjTT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4uRA27SJjTWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "af2bWkVSjTYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WUCmJA1GjTbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yKI4ryDmjTdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sPMnDFh-jTfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rhq1XtAVjTie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g8mLQswhjTk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BQ7pfFcOjTnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PXyxKGfsjTpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bflqe_xbjTr5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}